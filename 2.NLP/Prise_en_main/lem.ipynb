{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'Flavourings', 'Vitamins', 'and', 'Minerals', ':', 'Calcium', 'Carbonate', ',', 'Tricalcium', 'Phosphate', ',', 'Zinc', 'and', 'Iron', '(', 'mineral', 'nutrient', ')', ',', 'vitamin', 'C', '(', 'sodium', 'ascorbate', ')', ',', 'a', 'B', 'vitamin', '(', 'niacinamide', ')', ',', 'Vitamin', 'bs']\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle linguistique de SpaCy pour l'anglais\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Texte à lemmatiser\n",
    "text = \" Flavourings Vitamins and Minerals: Calcium Carbonate, Tricalcium Phosphate, Zinc and Iron (mineral nutrients), Vitamin C (sodium ascorbate), A B Vitamin (niacinamide), Vitamin Bs\"\n",
    "\n",
    "# Traiter le texte avec SpaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extraire les lemmes\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "print(lemmas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatization : this step involve reduce word to their base form or \" lemma \" , thus allow group different form of the same word and improve the effectiveness of text analysis . for example , the word \" eating \" become eat .\n"
     ]
    }
   ],
   "source": [
    "def lemmatize_text_english(text):\n",
    "    # Charger le modèle linguistique de SpaCy pour l'anglais\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Traiter le texte avec SpaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extraire et retourner les lemmes sous forme de texte\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "    return lemmatized_text\n",
    "\n",
    "# Texte à lemmatiser\n",
    "text = \"Lemmatization: this step involves reducing words to their base form or ”lemma”, thus allowing grouping different forms of the same word and improving the effectiveness of text analysis. For example, the word ”eating” becomes eat.\"\n",
    "\n",
    "# Appeler la fonction de lemmatisation en anglais\n",
    "lemmatized_result = lemmatize_text_english(text)\n",
    "\n",
    "# Afficher le texte lemmatisé en anglais\n",
    "print(lemmatized_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger les données nécessaires pour NLTK (si ce n'est pas déjà fait)\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Vitamins and Minerals: Calcium Carbonate, Tricalcium Phosphate, Zinc and Iron (mineral nutrients), Vitamin C (sodium ascorbate), A B Vitamin (niacinamide), Vitamin Bs\n",
      "Stemmed Text: vitamin and miner : calcium carbon , tricalcium phosphat , zinc and iron ( miner nutrient ) , vitamin c ( sodium ascorb ) , a b vitamin ( niacinamid ) , vitamin bs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\boss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def stem_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "input_text = \"Vitamins and Minerals: Calcium Carbonate, Tricalcium Phosphate, Zinc and Iron (mineral nutrients), Vitamin C (sodium ascorbate), A B Vitamin (niacinamide), Vitamin Bs\"\n",
    "\n",
    "stemmed_text = stem_text(input_text)\n",
    "print(\"Input Text:\", input_text)\n",
    "print(\"Stemmed Text:\", stemmed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanfordnlp\n",
      "  Downloading stanfordnlp-0.2.0-py3-none-any.whl (158 kB)\n",
      "     -------------------------------------- 158.8/158.8 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf in c:\\users\\boss\\anaconda3\\lib\\site-packages (from stanfordnlp) (4.23.3)\n",
      "Requirement already satisfied: requests in c:\\users\\boss\\anaconda3\\lib\\site-packages (from stanfordnlp) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\boss\\anaconda3\\lib\\site-packages (from stanfordnlp) (4.64.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\boss\\anaconda3\\lib\\site-packages (from stanfordnlp) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\boss\\anaconda3\\lib\\site-packages (from stanfordnlp) (1.12.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\boss\\anaconda3\\lib\\site-packages (from torch>=1.0.0->stanfordnlp) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\boss\\anaconda3\\lib\\site-packages (from requests->stanfordnlp) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\boss\\anaconda3\\lib\\site-packages (from requests->stanfordnlp) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\boss\\anaconda3\\lib\\site-packages (from requests->stanfordnlp) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\boss\\anaconda3\\lib\\site-packages (from requests->stanfordnlp) (1.26.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\boss\\anaconda3\\lib\\site-packages (from tqdm->stanfordnlp) (0.4.6)\n",
      "Installing collected packages: stanfordnlp\n",
      "Successfully installed stanfordnlp-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stanfordnlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\boss\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Cannot load model from C:\\Users\\boss\\stanfordnlp_resources\\en_ewt_models\\en_ewt_tokenizer.pt\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\stanfordnlp\\models\\tokenize\\trainer.py:82\u001b[0m, in \u001b[0;36mTrainer.load\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 82\u001b[0m     checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(filename, \u001b[39mlambda\u001b[39;49;00m storage, loc: storage)\n\u001b[0;32m     83\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m     \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    231\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\boss\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tokenizer.pt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstanfordnlp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m nlp \u001b[39m=\u001b[39m stanfordnlp\u001b[39m.\u001b[39;49mPipeline(lang\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m'\u001b[39;49m, processors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtokenize,lemma\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m doc \u001b[39m=\u001b[39m nlp(\u001b[39m\"\u001b[39m\u001b[39mMy cats were playing in the garden\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\stanfordnlp\\pipeline\\core.py:121\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, processors, lang, models_dir, treebank, use_gpu, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[39m# try to build processor, throw an exception if there is a requirements issue\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessors[processor_name] \u001b[39m=\u001b[39m NAME_TO_PROCESSOR_CLASS[processor_name](config\u001b[39m=\u001b[39;49mcurr_processor_config,\n\u001b[0;32m    122\u001b[0m                                                                               pipeline\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    123\u001b[0m                                                                               use_gpu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_gpu)\n\u001b[0;32m    124\u001b[0m \u001b[39mexcept\u001b[39;00m ProcessorRequirementsException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    125\u001b[0m     \u001b[39m# if there was a requirements issue, add it to list which will be printed at end\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\stanfordnlp\\pipeline\\processor.py:102\u001b[0m, in \u001b[0;36mUDProcessor.__init__\u001b[1;34m(self, config, pipeline, use_gpu)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vocab \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_up_model(config, use_gpu)\n\u001b[0;32m    103\u001b[0m \u001b[39m# run set up process\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39m# build the final config for the processor\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\stanfordnlp\\pipeline\\tokenize_processor.py:31\u001b[0m, in \u001b[0;36mTokenizeProcessor._set_up_model\u001b[1;34m(self, config, use_gpu)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer \u001b[39m=\u001b[39m Trainer(model_file\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mmodel_path\u001b[39;49m\u001b[39m'\u001b[39;49m], use_cuda\u001b[39m=\u001b[39;49muse_gpu)\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\stanfordnlp\\models\\tokenize\\trainer.py:16\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, args, vocab, model_file, use_cuda)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mif\u001b[39;00m model_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     \u001b[39m# load everything from file\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload(model_file)\n\u001b[0;32m     17\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[39m# build model from scratch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\stanfordnlp\\models\\tokenize\\trainer.py:85\u001b[0m, in \u001b[0;36mTrainer.load\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCannot load model from \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(filename))\n\u001b[1;32m---> 85\u001b[0m     sys\u001b[39m.\u001b[39;49mexit(\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m checkpoint[\u001b[39m'\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2047\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2044\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[0;32m   2045\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2046\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> 2047\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[0;32m   2048\u001b[0m                                                      value))\n\u001b[0;32m   2049\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2051\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[0;32m   2052\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[0;32m   2053\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:585\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[0;32m    578\u001b[0m     \u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \n\u001b[0;32m    580\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:452\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    449\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[0;32m    450\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    451\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 452\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m    453\u001b[0m             etype, evalue, (etb, chained_exc_ids),\n\u001b[0;32m    454\u001b[0m             chained_exceptions_tb_offset, context)\n\u001b[0;32m    455\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[0;32m    456\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[0;32m    458\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:1118\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1116\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1117\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m tb\n\u001b[1;32m-> 1118\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1119\u001b[0m     \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:1012\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1009\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m   1010\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[0;32m   1011\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1013\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1015\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1016\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:865\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[0;32m    857\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    858\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    862\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[0;32m    863\u001b[0m ):\n\u001b[0;32m    864\u001b[0m     \u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m    866\u001b[0m                                                            tb_offset)\n\u001b[0;32m    868\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:799\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[0;32m    797\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(etype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[0;32m    798\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 799\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[0;32m    803\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:854\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    848\u001b[0m     formatter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    849\u001b[0m options \u001b[39m=\u001b[39m stack_data\u001b[39m.\u001b[39mOptions(\n\u001b[0;32m    850\u001b[0m     before\u001b[39m=\u001b[39mbefore,\n\u001b[0;32m    851\u001b[0m     after\u001b[39m=\u001b[39mafter,\n\u001b[0;32m    852\u001b[0m     pygments_formatter\u001b[39m=\u001b[39mformatter,\n\u001b[0;32m    853\u001b[0m )\n\u001b[1;32m--> 854\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(stack_data\u001b[39m.\u001b[39;49mFrameInfo\u001b[39m.\u001b[39;49mstack_data(etb, options\u001b[39m=\u001b[39;49moptions))[tb_offset:]\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\stack_data\\core.py:546\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[1;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    531\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack_data\u001b[39m(\n\u001b[0;32m    532\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    536\u001b[0m         collapse_repeated_frames: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    537\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[\u001b[39m'\u001b[39m\u001b[39mFrameInfo\u001b[39m\u001b[39m'\u001b[39m, RepeatedFrames]]:\n\u001b[0;32m    538\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[39m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[39m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 546\u001b[0m     stack \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(iter_stack(frame_or_tb))\n\u001b[0;32m    548\u001b[0m     \u001b[39m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[0;32m    549\u001b[0m     \u001b[39m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[0;32m    550\u001b[0m     \u001b[39m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[0;32m    551\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\stack_data\\utils.py:98\u001b[0m, in \u001b[0;36miter_stack\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mwhile\u001b[39;00m frame_or_tb:\n\u001b[0;32m     97\u001b[0m     \u001b[39myield\u001b[39;00m frame_or_tb\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n\u001b[0;32m     99\u001b[0m         frame_or_tb \u001b[39m=\u001b[39m frame_or_tb\u001b[39m.\u001b[39mf_back\n\u001b[0;32m    100\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\stack_data\\utils.py:91\u001b[0m, in \u001b[0;36mis_frame\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m---> 91\u001b[0m     assert_(\u001b[39misinstance\u001b[39;49m(frame_or_tb, (types\u001b[39m.\u001b[39;49mFrameType, types\u001b[39m.\u001b[39;49mTracebackType)))\n\u001b[0;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(frame_or_tb, (types\u001b[39m.\u001b[39mFrameType,))\n",
      "File \u001b[1;32mc:\\Users\\boss\\anaconda3\\lib\\site-packages\\stack_data\\utils.py:172\u001b[0m, in \u001b[0;36massert_\u001b[1;34m(condition, error)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(error, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    171\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mAssertionError\u001b[39;00m(error)\n\u001b[1;32m--> 172\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline(lang='en', processors='tokenize,lemma')\n",
    "doc = nlp(\"My cats were playing in the garden\")\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(word.lemma)\n",
    "# Output: my cat be play in the garden\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
